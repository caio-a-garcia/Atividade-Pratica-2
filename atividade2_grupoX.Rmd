---
title: "atividade2_grupoX"
author: "Caio, Isabella e Murilo"
date: "2023-11-13"
output: html_document
---

# Atividade prática 2 - Produtividade Policial - Grupo X

## Introdução

Este Rmarkdown tem o objetivo de responder as perguntas da atitivade 2 de Aprendizado de Maquina II.

## Bibliotecas

Todas as bibliotecas utilizadas neste projeto:

```{r Bibliotecas, echo=True, results='hide'}
# Importando as bibliotecas utilizadas no projeto
library(tidyverse)
library(readxl)
library(stringi)
library(factoextra)
library(ggrepel)
```

## Manipulação dos Dados

Realizando as manipulações previstas no documento disponibilizado no blackboard.

```{r Leitura do Arquivo}
# Lendo arquivo xlsx
dados <- read_xlsx("produtividade_policial.xlsx")

# Visualizando uma parte da tabela
dados %>% 
  sample_n(10)
```

Removendo os caracteres especiais do nome das columas e os deixando em letras minúsuculas conforme documento do blackboard:

```{r Ajustando nome das colunas}
dados <- dados %>% 
  rename_with(~ stri_trans_general(.x, "Latin-ASCII") %>% 
                tolower())
```

## Tarefas

1.  Para este exercício, manipule os dados para considerar apenas os dados totais de cada indicador para cada região. Forneça o código que deixa os dados no seguinte formato.

```{r Realizando Transformações, warning=FALSE}
# Realizando as transformações necessarias
dados_transformados <- dados %>%
  pivot_longer(cols = jan:dez, names_to = "mes", values_to = "indicador") %>%
  group_by(regiao, ocorrencia, mes) %>%
  summarise(total = sum(indicador, na.rm = TRUE)) %>%
  group_by(regiao, ocorrencia) %>%
  summarise(total = sum(total, na.rm = TRUE)) %>%
  pivot_wider(names_from = "ocorrencia", values_from = "total")

# Visualizando os resultados
dados_transformados
```

2.  Realize o procedimento para obter as componentes principais deste conjunto de dados. Quantas componentes principais são necessárias para se explicar pelo menos 80% da variância dos dados?

```{r Aplicando PCA}
# Transformando tibble em dataframe
dados_transformados <- as.data.frame(dados_transformados)

# Transformando a coluna regiao em index
row.names(dados_transformados) <- dados_transformados$regiao

# Removendo a primeira coluna 
dados_transformados <- dados_transformados[,-1]

# Cálculando as componentes princiapais
pca_result <- prcomp(dados_transformados, scale = TRUE)

# Plotando gráfico de cotovelo com a biblioteca factoextra
fviz_eig(pca_result, addlabels = TRUE, main = "Gráfico de Cotovelo")
```

O gráfico de cotovelo evidência que a soma das duas primeiras componentes principais ultrapassa 80%, indicando que essas duas componentes são capazes de explicar pelo menos 89,6% da variância total dos dados.

3.  Obtenha as contribuições das preditoras para a primeira componente principal. Qual nome você daria para esta componente?

```{r Contribuições para a primeira componente}
# Obtendo as contribuições da primeira componente principal
cp1_contr <- pca_result$rotation[, 1]

# Ordenando as contribuições pelo valor absoluto
cp1_contr_ordenado <- cp1_contr[order(abs(cp1_contr), decreasing = TRUE)]

# Visualizar as contribuições ordenadas
print(cp1_contr_ordenado)
```

Observando as contribuições dessa componente principal, percebe-se que a grande maioria das variáveis preditoras possui pesos de contribuição semelhantes, com exceção das preditoras 'OCORRÊNCIAS DE APREENSÃO DE ENTORPECENTES(1)', 'OCORRÊNCIAS DE PORTE DE ENTORPECENTES' e 'Nº DE INFRATORES APREENDIDOS POR MANDADO'. Isso sugere que essa componente principal não é significativamente influenciada por crimes menos graves, que resultam apenas em apreensão ou advertência educativa por porte. Portanto, podemos interpretar esta componente como relacionada a "crimes de infração grave".

4.  Obtenha as contribuições das preditoras para a segunda componente principal. Qual nome você daria para esta componente?

```{r Contribuições para a segunda componente}
# Obtendo as contribuições da primeira componente principal
cp2_contr <- pca_result$rotation[, 2]

# Ordenando as contribuições pelo valor absoluto
cp2_contr_ordenado <- cp2_contr[order(abs(cp2_contr), decreasing = TRUE)]

# Visualizar as contribuições ordenadas
print(cp2_contr_ordenado)
```

Os resultados referentes à segunda componente de contribuição revelam um padrão praticamente oposto ao observado na primeira componente principal. Isso sugere que essa variável pode ser interpretada como uma contraparte inversa da primeira componente, sendo designada portanto como "crimes de infração leve".

No entanto, é importante destacar que a variável preditora que exerceu a maior influência nesta segunda componente não está necessariamente relacionada a um crime direto, mas sim a atos de execução de mandatos emitidos. Isso indica a necessidade de cautela ao interpretar ambas as componentes principais.

5.  Faça um gráfico de dispersão com as duas primeiras componentes principais. Com base nas respostas anteriores e neste gráfico, o que pode-se dizer sobre a Capital? E sobre a região de Ribeirão Preto? E Sorocaba?

```{r Gráfico de Dispersão}
# Plotando gráfico de dispersão
fviz_pca_biplot(pca_result, repel = TRUE, xlab = "PC1",
 ylab = "PC2")
```

A partir da análise do gráfico, observamos que a capital apresenta um comportamento distintivo em comparação com as demais cidades. Aparentemente, possui uma taxa mais baixa de "crimes de infração grave" e uma taxa mais elevada de "crimes de infração leve". Por outro lado, a região de Ribeirão Preto também se destaca em relação à maioria das outras cidades, exibindo uma baixa taxa de "crimes de infração leve" e uma taxa de "crimes de infração grave" não tão pequena quanto a capital, mas inferior às demais cidades.

No caso de Sorocaba, aparentemente, há um equilíbrio entre essas duas novas variáveis de infração geradas a partir das componentes principais.

6.  Análise de conglomerados

-   6.1. Execute o método k-means para identificar o número ótimo de clusters entre as regiões analisadas.

```{r Método do Cotovelo}
# Configurando semente aleatoria
set.seed(39)

# Como temos apenas 10 observações, iremos testar todas os numeros de K possiveis
k <- 2:10

# Criando tibble  
tibble(k = k) %>% 

  # Para cada valor de k, calcula a soma dos quadrados internos (withinss) usando kmeans
  mutate(w = map_dbl(k, ~ kmeans(dados_transformados, centers = .x, nstart = 10)$tot.withinss)) %>% 

  # Cria um gráfico de dispersão com uma linha conectando os pontos
  ggplot(aes(k, w)) + 
    geom_point() +  # Adiciona os pontos
    scale_x_continuous(breaks = k) +  # Define as quebras no eixo x
    geom_line()  # Adiciona uma linha conectando os ponto

```
Analisando o gráfico gerado, o número ótimo de cluster aparentemente é com 4 grupos.

```{r Executando Kmeand}
# Executando K-means com o numero ótimo de clusters
k_medias <- kmeans(dados_transformados, 
                   centers = 4)
# 
kmeans_labels <- k_medias$cluster

kmeans_labels
```


-   6.2. Execute o método k-means para identificar o número ótimo de clusters entre as regiões analisadas.

```{r}
# Obtendo as coordenadas do PCA
dados_pca <- pca_result$x

# Adicionar rótulos de cluster aos resultados do PCA
dados_pca_kmeans <- cbind(dados_pca, Cluster = as.factor(kmeans_labels))

# Converter a matriz para um data.frame
dados_pca_kmeans_df <- as.data.frame(dados_pca_kmeans)

# Plotando grafico de dispersão 
ggplot(dados_pca_kmeans_df, aes(x = PC1, y = PC2, color = Cluster, label = rownames(dados_pca_kmeans_df))) +
  geom_point(size = 3) +
  geom_text(nudge_y = 0.1, nudge_x = 0.1, size = 3, show.legend = FALSE) +
  labs(title = "Clusters Obtidos pelo K-means após PCA",
       x = "Primeira Componente Principal",
       y = "Segunda Componente Principal",
       color = "Cluster") +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black")
```
-   6.3. Analise os resultados dos métodos de clusterização e interprete os grupos obtidos;


-   6.4. Discuta as implicações práticas dos grupos identificados, considerando possíveis ações que a Secretaria de Segurança Pública de São Paulo pode realizar.










